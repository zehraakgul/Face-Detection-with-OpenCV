{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3437a50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "######################################################\n",
    "img1 = cv2.imread('resim1.png')\n",
    "img_gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.imread('resim2.png')\n",
    "img_gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img3 = cv2.imread('resim3.png')\n",
    "img_gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "img4 = cv2.imread('resim4.png')\n",
    "img_gray4 = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "img5 = cv2.imread('resim5.png')\n",
    "img_gray5 = cv2.cvtColor(img5, cv2.COLOR_BGR2GRAY)\n",
    "img6 = cv2.imread('resim6.png')\n",
    "img_gray6 = cv2.cvtColor(img6, cv2.COLOR_BGR2GRAY)\n",
    "img7 = cv2.imread('resim7.png')\n",
    "img_gray7 = cv2.cvtColor(img7, cv2.COLOR_BGR2GRAY)\n",
    "img8 = cv2.imread('resim8.png')\n",
    "img_gray8 = cv2.cvtColor(img8, cv2.COLOR_BGR2GRAY)\n",
    "img9 = cv2.imread('resim9.png')\n",
    "img_gray9 = cv2.cvtColor(img9, cv2.COLOR_BGR2GRAY)\n",
    "img10 = cv2.imread('resim10.png')\n",
    "img_gray10 = cv2.cvtColor(img10, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "up = np.concatenate((img1,img2,img3,img4,img5),axis=1)\n",
    "down = np.concatenate((img6,img7,img8,img9,img10),axis=1)\n",
    "img = np.concatenate((up,down),axis=0)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "fname = 'Test.png'\n",
    "cname  = 'haarcascade_frontalface_alt.xml'\n",
    "\n",
    "##########################################################\n",
    "#sapka icin\n",
    "def face_detect(img, cname):\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_hist = cv2.equalizeHist(img_gray)\n",
    "    face_cascade = cv2.CascadeClassifier(cname)\n",
    "    faces = face_cascade.detectMultiScale(img_hist)\n",
    "    return faces\n",
    "\n",
    "def face_detection(gray_img):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    faces = detector(gray_img)\n",
    "    return faces\n",
    "\n",
    "\n",
    "def landmark_detection(faces,gray_img):\n",
    "    landmark_detector = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") \n",
    "    for face in faces:\n",
    "        landmarks = landmark_detector(gray_img,face)\n",
    "        face_points = []\n",
    "        for n in range(68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            face_points.append([x,y])\n",
    "            face_points_array = np.array(face_points)\n",
    "        \n",
    "    return face_points_array\n",
    "\n",
    "\n",
    "def filter(img,points,scale=5,masked=False,cropped=True):\n",
    "    if masked:\n",
    "        mask = np.zeros_like(img)\n",
    "        mask = cv2.fillPoly(mask,[points],(255,255,255))\n",
    "        img = cv2.bitwise_and(img,mask)\n",
    "    if cropped:\n",
    "        bounding_box = cv2.boundingRect(points)\n",
    "        x,y,w,h = bounding_box\n",
    "        cropped_part = img[y:y+h,x:x+w]\n",
    "        cropped_part = cv2.resize(cropped_part,(0,0),None,scale,scale)\n",
    "        return cropped_part\n",
    "    else:\n",
    "        return mask\n",
    "\n",
    "\n",
    "faces1 = face_detection(img_gray1)\n",
    "face_landmarks1 = landmark_detection(faces1,img_gray1)\n",
    "img_lips1 = filter(img1,face_landmarks1[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces2 = face_detection(img_gray2)\n",
    "face_landmarks2 = landmark_detection(faces2,img_gray2)\n",
    "img_lips2 = filter(img2,face_landmarks2[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces3 = face_detection(img_gray3)\n",
    "face_landmarks3 = landmark_detection(faces3,img_gray3)\n",
    "img_lips3 = filter(img3,face_landmarks3[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces4 = face_detection(img_gray4)\n",
    "face_landmarks4 = landmark_detection(faces4,img_gray4)\n",
    "img_lips4 = filter(img4,face_landmarks4[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces5 = face_detection(img_gray5)\n",
    "face_landmarks5 = landmark_detection(faces5,img_gray5)\n",
    "img_lips5 = filter(img5,face_landmarks5[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces6 = face_detection(img_gray6)\n",
    "face_landmarks6 = landmark_detection(faces6,img_gray6)\n",
    "img_lips6 = filter(img6,face_landmarks6[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces7 = face_detection(img_gray7)\n",
    "face_landmarks7 = landmark_detection(faces7,img_gray7)\n",
    "img_lips7 = filter(img7,face_landmarks7[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces8 = face_detection(img_gray8)\n",
    "face_landmarks8 = landmark_detection(faces8,img_gray8)\n",
    "img_lips8 = filter(img8,face_landmarks8[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces9 = face_detection(img_gray9)\n",
    "face_landmarks9 = landmark_detection(faces9,img_gray9)\n",
    "img_lips9 = filter(img9,face_landmarks9[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "faces10 = face_detection(img_gray10)\n",
    "face_landmarks10 = landmark_detection(faces10,img_gray10)\n",
    "img_lips10 = filter(img10,face_landmarks10[49:61],3,masked=True,cropped=False)\n",
    "\n",
    "\n",
    "window = 'controls'\n",
    "cv2.namedWindow(window)\n",
    "def dudak(param):\n",
    "    global color\n",
    "    global color_\n",
    "    color_ = cv2.getTrackbarPos('DUDAK RENK','controls')\n",
    "    if color_ ==1:\n",
    "        color = (0,0,255)\n",
    "    elif color_ ==2:\n",
    "        color = (0,255,0)\n",
    "    elif color_ ==3:\n",
    "        color = (255,0,0)\n",
    "    elif color_==4:\n",
    "        color=(0,255,255)\n",
    "        \n",
    "    \n",
    "    img_color_lips1 = np.zeros_like(img_lips1)\n",
    "    img_color_lips1[:] = color\n",
    "    img_color_lips1 = cv2.bitwise_and(img_lips1,img_color_lips1)\n",
    "    img_color_lips1 = cv2.GaussianBlur(img_color_lips1,(7,7),10)\n",
    "\n",
    "    img_color_lips2 = np.zeros_like(img_lips2)\n",
    "    img_color_lips2[:] = color\n",
    "    img_color_lips2 = cv2.bitwise_and(img_lips2,img_color_lips2)\n",
    "    img_color_lips2 = cv2.GaussianBlur(img_color_lips2,(7,7),10)\n",
    "\n",
    "    img_color_lips3 = np.zeros_like(img_lips3)\n",
    "    img_color_lips3[:] = color\n",
    "    img_color_lips3 = cv2.bitwise_and(img_lips3,img_color_lips3)\n",
    "    img_color_lips3 = cv2.GaussianBlur(img_color_lips3,(7,7),10)\n",
    "\n",
    "    img_color_lips4 = np.zeros_like(img_lips4)\n",
    "    img_color_lips4[:] = color\n",
    "    img_color_lips4 = cv2.bitwise_and(img_lips4,img_color_lips4)\n",
    "    img_color_lips4 = cv2.GaussianBlur(img_color_lips4,(7,7),10)\n",
    "\n",
    "    img_color_lips5 = np.zeros_like(img_lips5)\n",
    "    img_color_lips5[:] = color\n",
    "    img_color_lips5 = cv2.bitwise_and(img_lips5,img_color_lips5)  \n",
    "    img_color_lips5 = cv2.GaussianBlur(img_color_lips5,(7,7),10) \n",
    "    \n",
    "    img_color_lips6 = np.zeros_like(img_lips6)\n",
    "    img_color_lips6[:] = color\n",
    "    img_color_lips6 = cv2.bitwise_and(img_lips6,img_color_lips6)\n",
    "    img_color_lips6 = cv2.GaussianBlur(img_color_lips6,(7,7),10)\n",
    "\n",
    "    img_color_lips7 = np.zeros_like(img_lips7)\n",
    "    img_color_lips7[:] = color\n",
    "    img_color_lips7 = cv2.bitwise_and(img_lips7,img_color_lips7)\n",
    "    img_color_lips7 = cv2.GaussianBlur(img_color_lips7,(7,7),10)\n",
    "\n",
    "    img_color_lips8 = np.zeros_like(img_lips8)\n",
    "    img_color_lips8[:] = color\n",
    "    img_color_lips8 = cv2.bitwise_and(img_lips8,img_color_lips8)\n",
    "    img_color_lips8 = cv2.GaussianBlur(img_color_lips8,(7,7),10)\n",
    "\n",
    "    img_color_lips9 = np.zeros_like(img_lips9)\n",
    "    img_color_lips9[:] = color \n",
    "    img_color_lips9 = cv2.bitwise_and(img_lips9,img_color_lips9) \n",
    "    img_color_lips9 = cv2.GaussianBlur(img_color_lips9,(7,7),10)\n",
    "\n",
    "    img_color_lips10 = np.zeros_like(img_lips10)\n",
    "    img_color_lips10[:] = color\n",
    "    img_color_lips10 = cv2.bitwise_and(img_lips10,img_color_lips10)\n",
    "    img_color_lips10 = cv2.GaussianBlur(img_color_lips10,(7,7),10)\n",
    "\n",
    "\n",
    "\n",
    "    final_image1 = cv2.addWeighted(img1,1,img_color_lips1,0.4,0)\n",
    "    final_image2 = cv2.addWeighted(img2,1,img_color_lips2,0.4,0)\n",
    "    final_image3 = cv2.addWeighted(img3,1,img_color_lips3,0.4,0)\n",
    "    final_image4 = cv2.addWeighted(img4,1,img_color_lips4,0.4,0)\n",
    "    final_image5 = cv2.addWeighted(img5,1,img_color_lips5,0.4,0)\n",
    "    final_image6 = cv2.addWeighted(img6,1,img_color_lips6,0.4,0)\n",
    "    final_image7 = cv2.addWeighted(img7,1,img_color_lips7,0.4,0)\n",
    "    final_image8 = cv2.addWeighted(img8,1,img_color_lips8,0.4,0)\n",
    "    final_image9 = cv2.addWeighted(img9,1,img_color_lips9,0.4,0)\n",
    "    final_image10 = cv2.addWeighted(img10,1,img_color_lips10,0.4,0)\n",
    "    \n",
    "    hori = np.concatenate((final_image1, final_image2, final_image3, final_image4, final_image5), axis=1)\n",
    "    hori_ = np.concatenate((final_image6, final_image7, final_image8, final_image9, final_image10), axis=1)\n",
    "    verti = np.concatenate((hori,hori_), axis=0)\n",
    "\n",
    "    cv2.imshow(window, verti)\n",
    "        \n",
    "def sapka(fname):\n",
    "    cname  = 'haarcascade_frontalface_alt.xml'\n",
    "    img = cv2.imread('Test.png')\n",
    "    faces = face_detect(img, cname)\n",
    "    hat = cv2.imread('kirmizisapka.png', -1)\n",
    "    for face in faces:\n",
    "        scale = face[3] / hat.shape[0] * 0.9\n",
    "        hat = cv2.resize(hat, (0, 0), fx=scale, fy=scale)\n",
    "        x_offset = int(face[0] + face[2] / 2 - hat.shape[1] / 2)\n",
    "        y_offset = int(face[1] - hat.shape[0] / 2)\n",
    "       \n",
    "        x1 = max(x_offset, 0)\n",
    "        x2 = min(x_offset + hat.shape[1], img.shape[1])\n",
    "        y1 = max(y_offset, 0)\n",
    "        y2 = min(y_offset + hat.shape[0], img.shape[0])\n",
    "        hat_x1 = max(0, -x_offset)\n",
    "        hat_x2 = hat_x1 + x2 - x1\n",
    "        hat_y1 = max(0, -y_offset)\n",
    "        hat_y2 = hat_y1 + y2 - y1\n",
    "        alpha_h = hat[hat_y1:hat_y2, hat_x1:hat_x2, 3] / 255\n",
    "        alpha = 1 - alpha_h\n",
    "        for c in range(3):\n",
    "            img[y1:y2, x1:x2, c] = alpha_h * hat[hat_y1:hat_y2, hat_x1:hat_x2, c] + alpha * img[y1:y2, x1:x2, c]\n",
    "    sapka_ = cv2.getTrackbarPos('SAPKA','controls')\n",
    "    if sapka_ == 1:\n",
    "        cv2.imshow(window, img)\n",
    "        \n",
    "cv2.createTrackbar('DUDAK RENK',window,1,4,dudak)\n",
    "cv2.createTrackbar('SAPKA',window,0,1,sapka)\n",
    "dudak(0)        \n",
    "sapka(fname)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a3cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
